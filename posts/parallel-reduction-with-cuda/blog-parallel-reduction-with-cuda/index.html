<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="写在前面 📚 版权声明 | Copyright Notice 本文内容参考并部分翻译自以下两篇资料： NVIDIA 官方 PPT（reduction.pdf） Medium 博客：7 Step Optimization of Parallel Reduction with CUDA 上述资料版权"><title>7 Step Optimization of Parallel Reduction with CUDA</title>
<link rel=canonical href=https://keqiye.github.io/posts/parallel-reduction-with-cuda/blog-parallel-reduction-with-cuda/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="7 Step Optimization of Parallel Reduction with CUDA"><meta property='og:description' content="写在前面 📚 版权声明 | Copyright Notice 本文内容参考并部分翻译自以下两篇资料： NVIDIA 官方 PPT（reduction.pdf） Medium 博客：7 Step Optimization of Parallel Reduction with CUDA 上述资料版权"><meta property='og:url' content='https://keqiye.github.io/posts/parallel-reduction-with-cuda/blog-parallel-reduction-with-cuda/'><meta property='og:site_name' content='Keqi的博客'><meta property='og:type' content='article'><meta property='article:section' content='Posts'><meta property='article:published_time' content='2025-05-22T00:00:00+00:00'><meta property='article:modified_time' content='2025-05-22T00:00:00+00:00'><meta name=twitter:title content="7 Step Optimization of Parallel Reduction with CUDA"><meta name=twitter:description content="写在前面 📚 版权声明 | Copyright Notice 本文内容参考并部分翻译自以下两篇资料： NVIDIA 官方 PPT（reduction.pdf） Medium 博客：7 Step Optimization of Parallel Reduction with CUDA 上述资料版权"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src="https://avatars.githubusercontent.com/u/175122082?v=4" width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🪐</span></figure><div class=site-meta><h1 class=site-name><a href=/>Keqi的博客</a></h1><h2 class=site-description>数学、物理与编程</h2></div></header><ol class=menu-social><li><a href=mailto:plloningye@gmail.com target=_blank title=E-mail rel=me><svg data-name="Livello 1" id="Livello_1" viewBox="0 0 128 128" xmlns="http://www.w3.org/2000/svg"><title/><path d="M116.73 31.83a3 3 0 00-4.2-.61L64.14 67.34a1 1 0 01-1.2.0L15.5 31.06a3 3 0 10-3.64 4.77l37.3 28.53-36.89 27.8A3 3 0 1015.88 97L54.11 68.14l5.18 4a7 7 0 008.43.06l5.44-4.06L111.84 97a3 3 0 103.59-4.81L78.17 64.35 116.12 36A3 3 0 00116.73 31.83z"/><path d="M113 19H15A15 15 0 000 34V94a15 15 0 0015 15h98a15 15 0 0015-15V34A15 15 0 00113 19zm9 75a9 9 0 01-9 9H15a9 9 0 01-9-9V34a9 9 0 019-9h98a9 9 0 019 9z"/></svg></a></li><li><a href=https://github.com/KeqiYe target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/posts/><span>文章</span></a></li><li><a href=/categories/><span>分类</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://keqiye.github.io/en/>English</option><option value=https://keqiye.github.io/ selected>中文</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#写在前面>写在前面</a></li><li><a href=#什么是-parallel-reduction-算法>什么是 Parallel Reduction 算法？</a><ol><li><a href=#树形归约模型tree-based-reduction>树形归约模型（Tree-based Reduction）</a></li><li><a href=#kernel-分解kernel-decomposition>Kernel 分解（Kernel Decomposition）</a></li><li><a href=#注意>注意！</a></li><li><a href=#性能衡量指标our-metrics>性能衡量指标（Our Metrics）</a></li></ol></li><li><a href=#reduce-0交错寻址法interleaved-addressing>REDUCE-0：交错寻址法（Interleaved Addressing）</a><ol><li><a href=#思路介绍>思路介绍</a></li><li><a href=#cuda-代码实现>CUDA 代码实现</a></li><li><a href=#该方法存在的问题>该方法存在的问题</a></li></ol></li><li><a href=#reduce-1交错寻址法-20interleaved-addressing-20>REDUCE-1：交错寻址法 2.0（Interleaved Addressing 2.0）</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/reduction/>Reduction
</a><a href=/categories/cuda/>CUDA
</a><a href=/categories/optimization/>Optimization</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/parallel-reduction-with-cuda/blog-parallel-reduction-with-cuda/>7 Step Optimization of Parallel Reduction with CUDA</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 22, 2025</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 6 分钟</time></div></footer></div></header><section class=article-content><h2 id=写在前面>写在前面</h2><blockquote><p>📚 <strong>版权声明 | Copyright Notice</strong></p><p>本文内容参考并部分翻译自以下两篇资料：</p><ul><li><a class=link href=https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf target=_blank rel=noopener>NVIDIA 官方 PPT（reduction.pdf）</a></li><li><a class=link href=https://medium.com/@rimikadhara/7-step-optimization-of-parallel-reduction-with-cuda-33a3b2feafd8 target=_blank rel=noopener>Medium 博客：7 Step Optimization of Parallel Reduction with CUDA</a></li></ul><p>上述资料版权归原作者所有。本文旨在学习和技术传播，仅供个人和学术使用。如有侵权，请联系删除。</p><p>This article is a study and partial translation based on the works above. All rights belong to the original authors. The content is shared for learning and research purposes only. Please contact for removal if there is any infringement.</p></blockquote><p>⚠️ <strong>若上述链接失效</strong>，读者可以在 Google 中使用关键词查找：<br><code>7 Step Optimization of Parallel Reduction with CUDA</code></p><p>本文将介绍如何优化 CUDA 中的并行规约算法 (Parallel Reduction)，并通过七个步骤逐步提升性能。尽管上述链接中作者已经说明的十分清楚。我这里还是会使用中文再走一边流程，一来为中文互联网提供参考资料，二来为我自己学习。</p><p>CUDA并行代码与串行代码的整体设计思路相差很大，虽然是按照线程来编写，但是要从Block层面去思考和设计。</p><h2 id=什么是-parallel-reduction-算法>什么是 Parallel Reduction 算法？</h2><p>让我们首先了解一下 Parallel Reduction 算法的基本概念。它是一种 <strong>数据并行原语</strong>，在 CUDA 中实现相对直接。简单来说，Parallel Reduction 的目标是通过 GPU 的线程层级结构并行地对向量、矩阵或张量进行归约操作。</p><p>这种归约是通过如 <code>sum()</code>、<code>min()</code>、<code>max()</code> 或 <code>avg()</code> 等操作来实现的，用于对数据进行聚合与简化。事实上，对一个数组求上述操作是十分简单的，如果想实现 CUDA 并行，核心难度在于访存设计。若处理不当，即使是这些“看似简单”的计算也可能变得耗时。</p><p>高效实现 Parallel Reduction 的一个原因是它们非常通用，并在许多应用中起着关键作用。我主要使用SPH研究小行星撞击，每一步SPH求解过程中，都需要进行包围盒计算，对应着 <code>min()</code>、<code>max()</code> 操作。</p><h3 id=树形归约模型tree-based-reduction>树形归约模型（Tree-based Reduction）</h3><p>并行归约可以被类比为一种“树状归约”（tree-based reduction）过程：数据在各线程块（thread block）之间逐层归约。</p><p>但这里出现了一个关键问题：</p><blockquote><p><strong>我们如何在不同线程块之间传递中间结果？</strong></p></blockquote><p>最直接的想法是使用“全局同步（global synchronization）” —— 先让每个线程块完成一部分计算，然后进行全局同步并继续递归处理。</p><p>然而，CUDA <strong>并不支持全局同步</strong>，因为这在硬件上开销极大，还可能导致死锁，只能使用少量线程块，限制性能提升。</p><p>📌 <strong>更实用的方案是：Kernel 分解（Kernel Decomposition）</strong></p><h3 id=kernel-分解kernel-decomposition>Kernel 分解（Kernel Decomposition）</h3><p>为了更高效地传递线程块间的中间结果，我们可以将一个大的 kernel 拆分为多个小 kernel。这种做法被称为 <strong>Kernel 分解</strong>。</p><p><img src=/images/tree-reduction.png loading=lazy alt="Tree-based Reduction"></p><p>Kernel 分解的优势包括：</p><ul><li>减少硬件与软件开销</li><li>提高资源利用率</li><li>避免线程块间同步</li><li>提升整体执行效率</li></ul><hr><h3 id=注意>注意！</h3><p>本文重点讲解规约（reduction）的基本思想，而非完整的最终实现。因此，每个 kernel 的执行结果并不是一个全局单一值，而是 <strong>每个 block 内部的规约结果</strong>。</p><p>具体来说：</p><ul><li>每个 block 负责处理若干个线程的(<code>blockDim</code>)数据，并在 block 内完成一次局部规约；</li><li>每个 block 的结果会被写入输出数组的 <code>blockIdx.x</code> 位置；</li><li>因此，最终输出数组的长度等于 <code>gridDim.x</code>（即 block 数量），而不是单个元素。</li></ul><hr><h3 id=性能衡量指标our-metrics>性能衡量指标（Our Metrics）</h3><p>我们衡量并行归约算法性能的两个关键指标是：</p><ul><li><strong>时间（Time）</strong></li><li><strong>带宽（Bandwidth）</strong></li></ul><p>这两个指标反映了 GPU 是否达到了峰值性能。我们希望在以下两方面进行优化：</p><ol><li><strong>提高数据读写效率</strong></li><li><strong>加快计算速度、提升线程利用率</strong></li></ol><p>一段理想的 GPU 程序，不仅运行快速，还能使大多数线程都在工作。</p><h2 id=reduce-0交错寻址法interleaved-addressing>REDUCE-0：交错寻址法（Interleaved Addressing）</h2><h3 id=思路介绍>思路介绍</h3><p>最朴素的一种并行归约方法是采用“交错寻址（Interleaved Addressing）”，作为我们优化过程的基础版本。在这种方法中：</p><ul><li>每个线程处理一组元素；</li><li>每轮归约时，线程将其当前值与一段距离内的另一个元素值相加；</li><li>每轮步长加倍，直到最终得出该 block 的归约结果。</li></ul><p>📘 例如，对于一个 1024 元素数组，使用 256 线程块，每个线程处理四个间隔为 256 的数据点。</p><p>这种方式可以确保：</p><ul><li>各线程并行工作，负载均衡；</li><li>线程间同步更简单；</li><li>便于 GPU 高效执行。</li></ul><h3 id=cuda-代码实现>CUDA 代码实现</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=o>//</span> <span class=n>REDUCTION</span> <span class=mi>0</span> <span class=err>–</span> <span class=n>Interleaved</span> <span class=n>Addressing</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=n>void</span> <span class=n>reduce0</span><span class=p>(</span><span class=ne>int</span> <span class=o>*</span><span class=n>g_in_data</span><span class=p>,</span> <span class=ne>int</span> <span class=o>*</span><span class=n>g_out_data</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>extern</span> <span class=n>__shared__</span> <span class=ne>int</span> <span class=n>sdata</span><span class=p>[];</span>  <span class=o>//</span> <span class=n>stored</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>shared</span> <span class=n>memory</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=o>//</span> <span class=n>Each</span> <span class=n>thread</span> <span class=n>loading</span> <span class=n>one</span> <span class=n>element</span> <span class=n>from</span> <span class=n>global</span> <span class=n>onto</span> <span class=n>shared</span> <span class=n>memory</span>
</span></span><span class=line><span class=cl>    <span class=n>unsigned</span> <span class=ne>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=o>.</span><span class=n>x</span><span class=p>;</span> <span class=o>//</span><span class=n>tid表示当前线程在所在</span> <span class=n>block</span> <span class=err>中的局部索引</span>
</span></span><span class=line><span class=cl>    <span class=n>unsigned</span> <span class=ne>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=o>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=o>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=o>.</span><span class=n>x</span><span class=p>;</span><span class=o>//</span><span class=n>i表示当前线程在整个</span> <span class=n>grid</span> <span class=err>中的全局线程编号</span>
</span></span><span class=line><span class=cl>    <span class=n>sdata</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=n>g_in_data</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=o>//</span> <span class=n>Reduction</span> <span class=n>method</span> <span class=o>--</span> <span class=n>occurs</span> <span class=ow>in</span> <span class=n>shared</span> <span class=n>memory</span> <span class=n>because</span> <span class=n>that</span><span class=s1>&#39;s where sdata is stored</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=n>unsigned</span> <span class=ne>int</span> <span class=n>s</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>s</span> <span class=o>&lt;</span> <span class=n>blockDim</span><span class=o>.</span><span class=n>x</span><span class=p>;</span> <span class=n>s</span> <span class=o>*=</span> <span class=mi>2</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>tid</span> <span class=o>%</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>s</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>sdata</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+=</span> <span class=n>sdata</span><span class=p>[</span><span class=n>tid</span> <span class=o>+</span> <span class=n>s</span><span class=p>];</span>   
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>tid</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>g_out_data</span><span class=p>[</span><span class=n>blockIdx</span><span class=o>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>sdata</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=该方法存在的问题>该方法存在的问题</h3><p>虽然这种方法是并行编程的良好基础，但它仍存在一些问题。让我们回顾一下性能指标，分析代码在计算和内存方面可能存在的低效之处。</p><p><strong>计算方面：</strong> 一个主要的计算低效是 <code>%</code> 操作符的使用。由于 <code>%</code> 涉及除法操作，而除法在底层是非常慢的操作，这会严重影响性能，特别是在大量线程频繁执行该操作的内核中。此外，交错寻址模式导致了严重的 warp 发散（divergence），因为同一个 warp 中的线程需要执行不同的分支路径（基于当前的 <code>if</code> 条件）。这种路径发散导致 warp 需要等待较慢的线程完成，造成阻塞，从而严重降低性能。具体而言，代码块：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    for(unsigned int s = 1; s &lt; blockDim.x; s *= 2){
</span></span><span class=line><span class=cl>        if (tid % (2 * s) == 0) {
</span></span><span class=line><span class=cl>            sdata[tid] += sdata[tid + s];   
</span></span><span class=line><span class=cl>        }
</span></span><span class=line><span class=cl>        __syncthreads();
</span></span><span class=line><span class=cl>    }
</span></span></code></pre></td></tr></table></div></div><p>第一个for，激活的线程为0，2，4&mldr;；第二次执行for循环，激活的线程为0，4，8&mldr; 显然，每个for循环中只有有50%，25%。。。的线程处于激活状态，这显然是我们不想看到了。我们希望尽可能多的线程都处于工作状态，至少在同一个warp中是如此。</p><p><strong>内存方面：</strong> 由于 warp 发散，该方法的内存访问模式不佳。每个线程访问的数据元素分布在整个数组中，导致内存访问分散而非合并访问（coalesced），从而造成带宽利用率低下和较高的内存延迟。这种分散访问会引起多次缓慢的内存事务，而非一次快速事务，未能充分利用 GPU 的内存带宽能力。不过，这个问题我们会在后续的优化中开始解决。具体来说
轮次 5: s = 16
if (tid % 32 == 0): 在Warp 0 (线程0-31)中，只有线程0在工作。
它读取 sdata[16]。
访存分析: 整个Warp为了满足线程0这一个读取请求，发起了一次内存事务。但这次事务中，只有1/32的数据被利用了。31/32的内存带宽被浪费了！</p><p>首先，我们先关注计算相关的问题，并进行下一步优化。</p><h2 id=reduce-1交错寻址法-20interleaved-addressing-20>REDUCE-1：交错寻址法 2.0（Interleaved Addressing 2.0）</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// REDUCTION 1 – Interleaved Addressing 2.0
</span></span><span class=line><span class=cl>__global__ void reduce1(int *g_in_data, int *g_out_data){
</span></span><span class=line><span class=cl>    extern __shared__ int sdata[];  // 储存在共享内存中
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    // 每个线程从全局内存加载一个元素到共享内存
</span></span><span class=line><span class=cl>    unsigned int tid = threadIdx.x;
</span></span><span class=line><span class=cl>    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
</span></span><span class=line><span class=cl>    sdata[tid] = g_in_data[i];
</span></span><span class=line><span class=cl>    __syncthreads();
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    // 归约操作 -- 在共享内存中进行
</span></span><span class=line><span class=cl>    for(unsigned int s = 1; s &lt; blockDim.x; s *= 2){
</span></span><span class=line><span class=cl>        // 注意步长 s *= 2：这导致了交错寻址
</span></span><span class=line><span class=cl>        int index = 2 * s * tid;    // 现在我们不再需要 if 条件带来的分化分支
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        // 确保不会越界访问
</span></span><span class=line><span class=cl>        if (index &lt; blockDim.x) 
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            sdata[index] += sdata[index + s];   // s 用来表示将被合并的偏移量
</span></span><span class=line><span class=cl>        }
</span></span><span class=line><span class=cl>        __syncthreads();
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // 线程0将最终结果写回全局内存
</span></span><span class=line><span class=cl>    if (tid == 0){
</span></span><span class=line><span class=cl>        g_out_data[blockIdx.x] = sdata[0];
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-ND 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/dense-tree-build/><div class=article-details><h2 class=article-title>基于稠密存储的并行树构建实现方案</h2></div></a></article><article><a href=/posts/cudatreecode/blog-post-treecode/><div class=article-details><h2 class=article-title>基于树结构的 SPH 粒子领域搜索</h2></div></a></article><article><a href=/posts/blog-post-2/><div class=article-details><h2 class=article-title>SPH 粒子领域搜索</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2025 Example Person</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>